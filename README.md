# AI Avatar Discussion Stream

Two autonomous AI agents with animated avatars discuss longevity and aging biology in real-time on YouTube. No human intervention required.

**ðŸŽ¥ [Watch Live Demo on YouTube](https://youtube.com/live/MfnclZWCSUk)**

---

## Features

âœ… **Autonomous AI Dialogue** â€” Groq LLM generates natural conversation between two distinct personalities  
âœ… **Text-to-Speech** â€” ElevenLabs voices with different tones for each agent  
âœ… **Lip-Sync Animation** â€” Mouth movements synchronized with speech  
âœ… **Real-Time Overlay** â€” Dynamic dialogue subtitles update during the stream  
âœ… **Live Streaming** â€” Direct integration with YouTube via OBS WebSocket  
âœ… **Transcript Logging** â€” Full conversation saved with timestamps

---

## Tech Stack

- **LLM**: Groq API (Llama 3.3 70B Versatile)
- **TTS**: ElevenLabs API
- **Streaming**: OBS Studio + WebSocket automation
- **Orchestration**: Python
- **Avatars**: AI-generated portraits (Artlist Nano Banana Pro)

---

## Project Structure

```
ai-avatar-stream/
â”‚
â”œâ”€â”€ main.py                  # Entry point â€” orchestrates the entire flow
â”œâ”€â”€ config.py                # All settings (agents, topics, timing)
â”œâ”€â”€ dialogue.py              # Groq LLM conversation logic
â”œâ”€â”€ tts.py                   # ElevenLabs speech generation + playback
â”œâ”€â”€ avatar.py                # OBS WebSocket control for avatar swapping
â”œâ”€â”€ overlay.py               # Rewrites dialogue.html for OBS browser source
â”œâ”€â”€ transcript.py            # Logs conversation with timestamps
â”œâ”€â”€ reset_overlay.py         # Resets dialogue display before streaming
â”‚
â”œâ”€â”€ dialogue.html            # OBS browser source overlay (auto-updated)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example             # API key template
â”‚
â”œâ”€â”€ audio/                   # Generated TTS files (created at runtime)
â”‚   â”œâ”€â”€ opening.mp3
â”‚   â”œâ”€â”€ turn_0.mp3
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ avatars/                 # AI-generated avatar portraits
    â”œâ”€â”€ agent1.png
    â”œâ”€â”€ agent1_talk_small.png
    â”œâ”€â”€ agent1_talk_medium.png
    â”œâ”€â”€ agent2.png
    â”œâ”€â”€ agent2_talk_small.png
    â””â”€â”€ agent2_talk_medium.png
```

---

## Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Set Up API Keys

```bash
cp .env.example .env
```

Edit `.env` and add your keys:
- `GROQ_API_KEY` â†’ Get from [console.groq.com](https://console.groq.com/)
- `ELEVENLABS_API_KEY` â†’ Get from [elevenlabs.io](https://elevenlabs.io/)

Optional: Customize voice IDs for each agent in `.env`

### 3. Test Locally

```bash
python main.py
```

You'll hear the agents talking and see dialogue in the terminal. Check `transcript.txt` for the full conversation log.

### 4. Stream to YouTube (Optional)

**Prerequisites:**
- OBS Studio installed
- YouTube live streaming enabled (24h activation period for new channels)

**OBS Setup:**

1. Create scene "AI Discussion"
2. Add sources (order matters):
   - **Color Source** â†’ black background
   - **Image** â†’ `avatars/agent1.png` (right side)
   - **Image** â†’ `avatars/agent2.png` (left side)
   - **Browser Source** â†’ Local file: `dialogue.html` (1000Ã—250px, bottom center)
   - **macOS Audio Capture** â†’ captures TTS audio
3. Settings â†’ Video â†’ 1280Ã—720, 30fps
4. Settings â†’ Stream â†’ Connect to YouTube

**Go Live:**

```bash
python reset_overlay.py    # Clear old dialogue
```

Start Streaming in OBS, wait 10 seconds, then:

```bash
python main.py
```

---

## Configuration

All settings are in `config.py`:

| Setting | Description | Default |
|---------|-------------|---------|
| `MAX_TURNS` | Number of back-and-forth exchanges | 5 |
| `PAUSE_BETWEEN_TURNS` | Silence between speakers (seconds) | 1 |
| `TOPICS` | Discussion topics pool | 8 aging biology topics |
| `AGENTS` | Agent personalities, voices, colors | Dr. Elena (optimist), Prof. Marcus (skeptic) |

---

## How It Works

1. **Dialogue Generation**: Groq LLM generates contextual responses based on agent personalities and conversation history
2. **Speech Synthesis**: ElevenLabs converts text to speech with distinct voices
3. **Avatar Animation**: Python controls OBS via WebSocket to swap avatar images (idle â†” talking states)
4. **Overlay Update**: `dialogue.html` is rewritten each turn, OBS browser source auto-refreshes
5. **Audio Playback**: TTS plays through system audio, OBS captures it for the stream
6. **Logging**: Every message saved to `transcript.txt` with timestamps

---

## Agents

**Dr. Elena** (Agent 1)  
*Optimistic molecular biologist*  
Believes aging can be reversed with the right interventions. References recent research enthusiastically.

**Prof. Marcus** (Agent 2)  
*Skeptical gerontologist*  
Demands rigorous evidence. Points out flaws in reasoning respectfully.

Both agents keep responses to 1-2 sentences for natural pacing.

---

## Demo

**Live Stream:** [https://youtube.com/live/MfnclZWCSUk](https://youtube.com/live/MfnclZWCSUk)

The stream demonstrates:
- Autonomous conversation (no human input during recording)
- Real-time dialogue updates
- Synchronized avatar mouth animation
- Natural topic transitions

---

## Notes

- **Lip-sync**: Uses static image swapping (idle/small/medium mouth states) rather than true video lip-sync
- **Avatar quality**: Photorealistic AI-generated portraits with natural skin texture
- **Context window**: Agents remember the last 6 messages for conversational coherence
- **Topic switching**: Automatically changes topics every 8 turns

---

## License

MIT